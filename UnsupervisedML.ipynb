{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the chemical space by Principal Component Analysis (PCA) and clustering\n",
    "\n",
    "In this workflow, we will analyze compounds binding to different targets with the aim to cluster molecules with similar properties. \n",
    "\n",
    "Can the compounds be separated using unsupervised learning (PCA & clustering) based on their target class?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Descriptors,Crippen, AllChem\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databases of molecules\n",
    "\n",
    "The library contains molecules in SMILES codes (and other representations and information) binding to 5 different protein targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.read_table('BDBcomp_50025598.tsv',sep='\\t')\n",
    "tmp.loc[:,'TargetID'] = 0\n",
    "tmp1=pd.read_table('BDBcomp_191.tsv',sep='\\t')\n",
    "tmp1.loc[:,'TargetID'] = 1\n",
    "tmp = pd.concat([tmp,tmp1],axis=0)\n",
    "tmp1=pd.read_table('BDBpoly_1201.tsv',sep='\\t')\n",
    "tmp1.loc[:,'TargetID'] = 2\n",
    "tmp = pd.concat([tmp,tmp1],axis=0)\n",
    "tmp1=pd.read_table('BDBpoly_1949.tsv',sep='\\t')\n",
    "tmp1.loc[:,'TargetID'] = 3\n",
    "tmp = pd.concat([tmp,tmp1],axis=0)\n",
    "tmp1=pd.read_table('BDBcomp_304.tsv',sep='\\t')\n",
    "tmp1.loc[:,'TargetID'] = 4\n",
    "tmp = pd.concat([tmp,tmp1],axis=0)\n",
    "\n",
    "table = tmp.loc[:,('Ligand SMILES', 'Ligand InChI', 'Target Name Assigned by Curator or DataSource', 'TargetID', 'IC50 (nM)')]\n",
    "table.rename(columns = {'Ligand SMILES':'SMILES', 'Target Name Assigned by Curator or DataSource':'Target', 'Ligand InChI':'InChI'}, inplace = True)\n",
    "table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "class0 = table.index[table.TargetID == 0]\n",
    "class1 = table.index[table.TargetID == 1]\n",
    "class2 = table.index[table.TargetID == 2]\n",
    "class3 = table.index[table.TargetID == 3]\n",
    "class4 = table.index[table.TargetID == 4]\n",
    "print(len(class0), len(class1), len(class2), len(class3), len(class4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s take a look at the first 10 elements of our table of compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of molecular descriptors \n",
    "\n",
    "We use RDKIT to calculate a few molecular descriptors (1D & 2D). \n",
    "\n",
    "Moreover, a list of all descriptor that can be calculated using RDKIT can be found https://www.rdkit.org/docs/GettingStartedInPython.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================\n",
    "## PLACE TO CHANGE:\n",
    "Add or replace descriptors;\n",
    "see http://rdkit.org/docs/source/rdkit.Chem.rdMolDescriptors.html for other desciptors.\n",
    "\n",
    "For addition: CalcNumAliphaticRings, CalcNumAromaticRings, CalcNumHeterocycles, CalcNumRings, CalcRadiusOfGyration, CalcSpherocityIndex\n",
    "\n",
    "For replacement: GetUSR, GetUSRCAT, GetMorganFingerprint, GetMACCSKeysFingerprint, GetAtomPairFingerprint, CalcWHIM\n",
    "\n",
    "Example:\n",
    "```python\n",
    "m2=Chem.AddHs(mol)\n",
    "AllChem.EmbedMolecule(m2)\n",
    "desc_vec = Chem.rdMolDescriptors.GetUSR(m2)\n",
    "```\n",
    "desc_vec is in form of a vector and needs to be translated into individual columns of pandas table to be used in the same manner as individual descriptors.\n",
    "\n",
    "========================================================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the descriptors and add them to our table\n",
    "for i in table.index:\n",
    "    mol=Chem.MolFromSmiles(table.loc[i,'SMILES'])\n",
    "    table.loc[i,'MolWt']=Descriptors.ExactMolWt (mol)\n",
    "    table.loc[i,'TPSA']=Chem.rdMolDescriptors.CalcTPSA(mol) #Topological Polar Surface Area\n",
    "    table.loc[i,'nRotB']=Descriptors.NumRotatableBonds (mol) #Number of rotable bonds\n",
    "    table.loc[i,'HBD']=Descriptors.NumHDonors(mol) #Number of H bond donors\n",
    "    table.loc[i,'HBA']=Descriptors.NumHAcceptors(mol) #Number of H bond acceptors\n",
    "    table.loc[i,'LogP']=Descriptors.MolLogP(mol) #LogP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we will get a table with all descriptors for each molecule (SMILES code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------\n",
    "### Principal Component Analysis of calculated molecular descriptors (PCA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================\n",
    "## PLACE TO CHANGE\n",
    "\n",
    "other descriptors\n",
    "\n",
    "========================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = table.loc[:, ['MolWt', 'TPSA', 'nRotB', 'HBD','HBA', 'LogP']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "\n",
    "A very important step is performing a standardization of the scales of the descriptors. Scales differences in PCA modify the variance distribution during PCA. More info about this topic can be found https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_std = StandardScaler().fit_transform(descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Now, we are ready to calculate the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "descriptors_2d = pca.fit_transform(descriptors_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s add the PCA data to a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_pca= pd.DataFrame(descriptors_2d)\n",
    "descriptors_pca.index = table.index\n",
    "descriptors_pca.columns = ['PC{}'.format(i+1) for i in descriptors_pca.columns]\n",
    "descriptors_pca.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained variance\n",
    "\n",
    "We can check the explained variance to see the variance explained by each component from PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_) \n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also, we can plot such data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.figure(figsize=(8,6))\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3)*100)\n",
    "plt.plot([i+1 for i in range(len(var))],var,'k-',linewidth=2)\n",
    "plt.xticks([i+1 for i in range(len(var))])\n",
    "plt.ylabel('% Variance Explained',fontsize=16,fontweight='bold')\n",
    "plt.xlabel('Pincipal Component (PC)',fontsize=16,fontweight='bold')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.tick_params ('both',width=2,labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the PC1 and PC2 explain 89 % of the variability. So we can plot PC1 vs PC2 to see the distribution of our compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(descriptors_pca['PC1'][class0],descriptors_pca['PC2'][class0],'o',color='k')\n",
    "ax.plot(descriptors_pca['PC1'][class1],descriptors_pca['PC2'][class1],'o',color='b')\n",
    "ax.plot(descriptors_pca['PC1'][class2],descriptors_pca['PC2'][class2],'o',color='g')\n",
    "ax.plot(descriptors_pca['PC1'][class3],descriptors_pca['PC2'][class3],'o',color='r')\n",
    "ax.plot(descriptors_pca['PC1'][class4],descriptors_pca['PC2'][class4],'o',color='y')\n",
    "ax.set_title ('Principal Component Analysis',fontsize=16,fontweight='bold',family='sans-serif')\n",
    "ax.set_xlabel ('PC1',fontsize=14,fontweight='bold')\n",
    "ax.set_ylabel ('PC2',fontsize=14,fontweight='bold')\n",
    "\n",
    "plt.tick_params ('both',width=2,labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this plot is simple and we cannot identify compound clusters easily. For such purpose, we can perform clustering analysis using the PCA values to identify compound groups by mathematical approaches. Moreover, PC1 vs PC2 (or any other combination) won´t give us information about which feature (descriptor) is more important to explain the variance of our values.\n",
    "\n",
    "For this example, we will identify the most important feature (descriptor), and we identify compound clusters by the k-means clustering algorithm. For more info about k-means, you can look at skit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering and main features identification\n",
    "\n",
    "The first step for this analysis is to re-scale our PCA values from -1 to 1. This is a typical procedure for distance-based clustering such as k-means clustering where both componenets are equally weighted in the distance calculation. It also allows us to analyze our data inside of the covariance cycle of the features (descriptors). Fur such purpose we type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This normalization will be performed just for PC1 and PC2, but can be done for all the components.\n",
    "scale1 = 1.0/(max(descriptors_pca['PC1']) - min(descriptors_pca['PC1']))\n",
    "scale2 = 1.0/(max(descriptors_pca['PC2']) - min(descriptors_pca['PC2']))\n",
    "\n",
    "# And we add the new values to our PCA table\n",
    "descriptors_pca['PC1_normalized']=[i*scale1 for i in descriptors_pca['PC1']]\n",
    "descriptors_pca['PC2_normalized']=[i*scale2 for i in descriptors_pca['PC2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_pca.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "#ax.plot(descriptors_pca['PC1_normalized'],descriptors_pca['PC2_normalized'],'o',color='k')\n",
    "ax.plot(descriptors_pca['PC1_normalized'][class0],descriptors_pca['PC2_normalized'][class0],'o',color='k')\n",
    "ax.plot(descriptors_pca['PC1_normalized'][class1],descriptors_pca['PC2_normalized'][class1],'o',color='b')\n",
    "ax.plot(descriptors_pca['PC1_normalized'][class2],descriptors_pca['PC2_normalized'][class2],'o',color='g')\n",
    "ax.plot(descriptors_pca['PC1_normalized'][class3],descriptors_pca['PC2_normalized'][class3],'o',color='r')\n",
    "ax.plot(descriptors_pca['PC1_normalized'][class4],descriptors_pca['PC2_normalized'][class4],'o',color='y')\n",
    "\n",
    "ax.set_title ('Principal Component Analysis',fontsize=16,fontweight='bold',family='sans-serif')\n",
    "ax.set_xlabel ('PC1',fontsize=14,fontweight='bold')\n",
    "ax.set_ylabel ('PC2',fontsize=14,fontweight='bold')\n",
    "\n",
    "plt.tick_params ('both',width=2,labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the distribution of the points is the same as before, however, the scale now is from -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "\n",
    "K-means clustering is an algorithm in which the user must define the number of clusters. However, in order to mathematically select a number of clusters for a group of points based on distribution, different algorithms can be applied. For instance, we will use the silhouette-based algorithm to identify the best number of clusters for our distribution. More info about silhouette algorithm can be found https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html and here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7]\n",
    "for n_clusters in range_n_clusters:\n",
    "    fig, (ax1,ax2,ax3)= plt.subplots(1, 3)\n",
    "    fig.set_size_inches(8, 4)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = kmeans.fit_predict(descriptors_pca[['PC1_normalized','PC2_normalized']])\n",
    "    silhouette_avg = silhouette_score(descriptors_pca[['PC1_normalized','PC2_normalized']], cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    sample_silhouette_values = silhouette_samples(descriptors_pca[['PC1_normalized','PC2_normalized']], cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(descriptors_pca['PC1_normalized'], descriptors_pca['PC2_normalized'], \n",
    "                marker='.', s=30, lw=0, alpha=0.7,c=colors, edgecolor='k')\n",
    "\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = kmeans.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC1\")\n",
    "    ax2.set_ylabel(\"PC2\")\n",
    "\n",
    "\n",
    "    ax3.scatter(descriptors_pca['PC1_normalized'][class0],descriptors_pca['PC2_normalized'][class0],marker='.', c='k', alpha=0.7, s=30, edgecolor='k')\n",
    "    ax3.scatter(descriptors_pca['PC1_normalized'][class1],descriptors_pca['PC2_normalized'][class1],marker='.', c='b', alpha=0.7, s=30, edgecolor='b')\n",
    "    ax3.scatter(descriptors_pca['PC1_normalized'][class2],descriptors_pca['PC2_normalized'][class2],marker='.', c='g', alpha=0.7, s=30, edgecolor='g')\n",
    "    ax3.scatter(descriptors_pca['PC1_normalized'][class3],descriptors_pca['PC2_normalized'][class3],marker='.', c='r', alpha=0.7, s=30, edgecolor='r')\n",
    "    ax3.scatter(descriptors_pca['PC1_normalized'][class4],descriptors_pca['PC2_normalized'][class4],marker='.', c='y', alpha=0.7, s=30, edgecolor='y')\n",
    "\n",
    "    ax3.set_title(\"Target classes.\")\n",
    "    ax3.set_xlabel(\"PC1\")\n",
    "    ax3.set_ylabel(\"PC2\")\n",
    "\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As higher the silhouette_score the better cluster distribution.\n",
    "\n",
    "Despite this fact, let us here use 5 clusters for the following analysis (since we know that we have five different protein targets; although its use would be \"supervising\" the procedure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=10) # We define the best number of clusters\n",
    "clusters = kmeans.fit(descriptors_pca[['PC1_normalized','PC2_normalized']]) #PC1 vs PC2 (normalized values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the calculation of clusters is done, we can add the result to our PCA table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_pca['Cluster_PC1_PC2'] = pd.Series(clusters.labels_, index=table.index)\n",
    "\n",
    "descriptors_pca.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything together\n",
    "\n",
    "We will plot PC1 vs PC2 data. Each cluster will have a different color, and we will find the main feature for each principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================\n",
    "## PLACE TO CHANGE (OR HIDE)\n",
    "========================================================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "\n",
    "color_code={ 0:        'magenta',\\\n",
    "             1.0:      'orange',\\\n",
    "             2.0:      'cyan',\\\n",
    "             3.0:      'green',\\\n",
    "             4.0:      'blue',\\\n",
    "             5.0:      'yellow',\\\n",
    "             6.0:      'red',\n",
    "             7.0:      'brown',\n",
    "             }\n",
    "\n",
    "for i in descriptors_pca.index: \n",
    "        ax.plot(descriptors_pca.loc[i].at['PC1_normalized'],descriptors_pca.loc[i].at['PC2_normalized'],\n",
    "                    c=color_code[descriptors_pca.loc[i].at['Cluster_PC1_PC2']],\n",
    "                    marker='o',markersize=8,markeredgecolor='k',alpha=0.3)\n",
    "        \n",
    "\n",
    "plt.xlabel ('PC1',fontsize=14,fontweight='bold')\n",
    "ax.xaxis.set_label_coords(0.98, 0.45)\n",
    "plt.ylabel ('PC2',fontsize=14,fontweight='bold')\n",
    "ax.yaxis.set_label_coords(0.45, 0.98)\n",
    "plt.tick_params ('both',width=2,labelsize=12)\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "lab=['MolWt', 'TPSA', 'nRotB', 'HBD','HBA', 'LogP'] #Feature labels\n",
    "\n",
    "l=np.transpose(pca.components_[0:2, :]) ## We will get the components eigenvectors (main features) for PC1 and PC2\n",
    "\n",
    "n = l.shape[0]\n",
    "for i in range(n):\n",
    "    plt.arrow(0, 0, l[i,0], l[i,1],color= 'k',alpha=0.6,linewidth=1.2,head_width=0.025)\n",
    "    plt.text(l[i,0]*1.25, l[i,1]*1.25, lab[i], color = 'k',va = 'center', ha = 'center',fontsize=11)\n",
    "\n",
    "circle = plt.Circle((0,0), 1, color='gray', fill=False,clip_on=True,linewidth=1.5,linestyle='--')\n",
    "ax.add_artist(circle)\n",
    "plt.xlim(-1.2,1.2)\n",
    "plt.ylim(-1.2,1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we can identify the features that correlate positively and negatively with PC1  and with PC2. Additionally, we can identify the \"most important\" feature (descriptor) because of the vector length. And also we can see the different clusters we identified by the silhouette-based algorithm.\n",
    "\n",
    "Finally, we can merge our tables to keep the data in a single table or file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=table.join(descriptors_pca)\n",
    "\n",
    "table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving values from a pandas table to a .csv file is very easy. You just need to type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('shallow_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b27a49d05b1edc481c11a586dad53c11bdcb63128eeca144f8ebcf35b86ec5ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
